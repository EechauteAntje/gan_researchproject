{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Jazz music with this notebook\n",
    "\n",
    "In this note book you can generate jazz music with the help of musegan"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make a conda environment with python 3.6"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to install:\n",
    "- cudatoolkit\n",
    "- cudnn\n",
    "- tensorflow\n",
    "- music21\n",
    "- imageio\n",
    "- matplotlib\n",
    "- scikit-learn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run all of the imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\antje\\anaconda3\\envs\\musegan\\lib\\site-packages\\requests\\__init__.py:104: RequestsDependencyWarning: urllib3 (1.26.14) or chardet (5.0.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "from music21 import converter, instrument, note, chord, stream\n",
    "import sys\n",
    "import numpy as np\n",
    "from imageio import imwrite\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy import vstack\n",
    "from numpy.random import randn\n",
    "from numpy.random import randint\n",
    "from tensorflow.keras.datasets.mnist import load_data\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Reshape\n",
    "from tensorflow.keras.layers import Flatten,BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Input\n",
    "from tensorflow.keras.layers import Conv2DTranspose\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adagrad\n",
    "from matplotlib import pyplot\n",
    "from IPython.display import clear_output\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "import pickle\n",
    "from decimal import Decimal\n",
    "import re\n",
    "\n",
    "import glob\n",
    "import random\n",
    "\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the models and the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(106, 106)\n",
      "(200, 106, 106, 1)\n",
      "[0. 1.]\n"
     ]
    }
   ],
   "source": [
    "# load pixel values from a file\n",
    "with open('./files/pixels.pkl', 'rb') as f:\n",
    "    pixels = pickle.load(f)\n",
    "\n",
    "# load images from a file\n",
    "with open('./files/imgs.pkl', 'rb') as f:\n",
    "    imgs = pickle.load(f)\n",
    "\n",
    "# if you get the following result, you are good to go\n",
    "print(imgs[0].size) # (106, 106, 1)\n",
    "print(pixels.shape) # (200, 106, 106, 1)\n",
    "print(np.unique(pixels)) # [0. 1.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "g_model = load_model('./files/cgan_generator.h5')\n",
    "d_model = load_model('./files/cgan_discriminator.h5')\n",
    "gan_model = load_model('./files/cgan_gan.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the music. \n",
    "This generates a random music piece."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 100\n",
    "n_samples = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 106, 106, 1)\n"
     ]
    }
   ],
   "source": [
    "def generate_latent_points(latent_dim, n_samples):\n",
    "    x_input = randn(latent_dim * n_samples)\n",
    "    x_input = x_input.reshape(n_samples, latent_dim)\n",
    "    return x_input\n",
    "model = g_model\n",
    "latent_points = generate_latent_points(latent_dim,n_samples)\n",
    "X = g_model.predict(latent_points)\n",
    "print(X.shape)\n",
    "for i in range(n_samples):\n",
    "    array = np.array(X[i].reshape(106,106),dtype = np.uint8)\n",
    "    array*= 255\n",
    "    new_image = Image.fromarray(array,'L')\n",
    "    new_image = new_image.save(f'./compositions/composition{i}.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This converts the png file to midi file. The midi files are in the folder 'compositions'. The filename looks like this: \n",
    "- composition[number of different midifiles].mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowerBoundNote = 21\n",
    "def column2notes(column):\n",
    "    notes = []\n",
    "    for i in range(len(column)):\n",
    "        if column[i] > 255/2:\n",
    "            notes.append(i+lowerBoundNote)\n",
    "    return notes\n",
    "\n",
    "resolution = 0.25\n",
    "def updateNotes(newNotes,prevNotes): \n",
    "    res = {} \n",
    "    for note in newNotes:\n",
    "        if note in prevNotes:\n",
    "            res[note] = prevNotes[note] + resolution\n",
    "        else:\n",
    "            res[note] = resolution\n",
    "    return res\n",
    "\n",
    "def image2midi(image_path):\n",
    "    with Image.open(image_path) as image:\n",
    "        im_arr = np.frombuffer(image.tobytes(), dtype=np.uint8)\n",
    "        try:\n",
    "            im_arr = im_arr.reshape((image.size[1], image.size[0]))\n",
    "        except:\n",
    "            im_arr = im_arr.reshape((image.size[1], image.size[0],3))\n",
    "            im_arr = np.dot(im_arr, [0.33, 0.33, 0.33])\n",
    "            print(\"Image is not grayscale, converting to grayscale\")\n",
    "\n",
    "    \"\"\" convert the output from the prediction to notes and create a midi file\n",
    "        from the notes \"\"\"\n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "\n",
    "    # create note and chord objects based on the values generated by the model\n",
    "\n",
    "    prev_notes = updateNotes(im_arr.T[0,:],{})\n",
    "    for column in im_arr.T[1:,:]:\n",
    "        notes = column2notes(column)\n",
    "        # pattern is a chord\n",
    "        notes_in_chord = notes\n",
    "        old_notes = prev_notes.keys()\n",
    "        for old_note in old_notes:\n",
    "            if not old_note in notes_in_chord:\n",
    "                new_note = note.Note(old_note,quarterLength=prev_notes[old_note])\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                if offset - prev_notes[old_note] >= 0:\n",
    "                    new_note.offset = offset - prev_notes[old_note]\n",
    "                    output_notes.append(new_note)\n",
    "                elif offset == 0:\n",
    "                    new_note.offset = offset\n",
    "                    output_notes.append(new_note)                    \n",
    "                else:\n",
    "                    print(offset,prev_notes[old_note],old_note)\n",
    "\n",
    "        prev_notes = updateNotes(notes_in_chord,prev_notes)\n",
    "\n",
    "        # increase offset each iteration so that notes do not stack\n",
    "        offset += resolution\n",
    "\n",
    "    for old_note in prev_notes.keys():\n",
    "        new_note = note.Note(old_note,quarterLength=prev_notes[old_note])\n",
    "        new_note.storedInstrument = instrument.Piano()\n",
    "        new_note.offset = offset - prev_notes[old_note]\n",
    "\n",
    "        output_notes.append(new_note)\n",
    "\n",
    "    prev_notes = updateNotes(notes_in_chord,prev_notes)\n",
    "\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "\n",
    "    midi_stream.write('midi', fp='./compositions/'+image_path.split(\"/\")[-1].replace(\".png\",\".mid\"))\n",
    "\n",
    "for i in range(n_samples):\n",
    "    image2midi(f'./compositions/composition{i}.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plays the midi samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <div id='midiPlayerDiv2411'></div>\n",
       "                <link rel=\"stylesheet\" href=\"//cuthbertLab.github.io/music21j/css/m21.css\"\n",
       "                    type=\"text/css\" />\n",
       "                <script>\n",
       "                require.config({\n",
       "                    paths: {'music21': '//cuthbertLab.github.io/music21j/src/music21'}\n",
       "                });\n",
       "                require(['music21'], function() {\n",
       "                               mp = new music21.miditools.MidiPlayer();\n",
       "                               mp.addPlayer('#midiPlayerDiv2411');\n",
       "                               mp.base64Load('data:audio/midi;base64,TVRoZAAAAAYAAQACBABNVHJrAAAAFAD/UQMHoSAA/1gEBAIYCIgA/y8ATVRyawAAAZ8A/wMAAOAAQADAAIgAkDxaAJB7WoIAgDwAAIB7AJAAkFlaggCAWQCQAJBLWoYAgEsAiACQQVqCAIBBAIoAkDFaAJAzWoIAgDEAAJBFWoIAkEdahACAMwCCAIBHAIIAkDVaAJA9WgCQQFoAkENaAJBVWoIAgDUAAIA9AIIAkDVaggCANQCCAIBAAACQNVoAkElaggCARQAAgEMAAIBVAACANQCEAJAzWoIAgEkAAJBLWoQAgDMAAJBNWoIAgE0AhACASwCGAJBBWoIAgEEAhgCQZVqCAIBlAACQaFqCAIBoAIYAkDlahACQI1oAkDZaAJA7WoIAkD1aggCAIwAAkDBaggCAOQAAgDYAAJAzWoIAgDMAAJA8WgCQOVqEAIA9AACAPACCAIAwAACQN1qCAIA7AACQNVqCAIA5AIIAgDcAAIA1AI4AkE1aggCATQCEAJBAWgCQPVqCAJBBWoIAkD5aAJA/WoIAgD4AggCAQQAAgD8AggCAQACCAIA9AI4AkDNaggCAMwCEAJBJWoIAkEtaggCASQCGAIBLAIgA/y8A');\n",
       "                        });\n",
       "                </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <div id='midiPlayerDiv3321'></div>\n",
       "                <link rel=\"stylesheet\" href=\"//cuthbertLab.github.io/music21j/css/m21.css\"\n",
       "                    type=\"text/css\" />\n",
       "                <script>\n",
       "                require.config({\n",
       "                    paths: {'music21': '//cuthbertLab.github.io/music21j/src/music21'}\n",
       "                });\n",
       "                require(['music21'], function() {\n",
       "                               mp = new music21.miditools.MidiPlayer();\n",
       "                               mp.addPlayer('#midiPlayerDiv3321');\n",
       "                               mp.base64Load('data:audio/midi;base64,TVRoZAAAAAYAAQACBABNVHJrAAAAFAD/UQMHoSAA/1gEBAIYCIgA/y8ATVRyawAAAREA/wMAAOAAQADAAIgAkDxaAJB7WoIAgDwAAIB7AJwAkCNahACAIwAAkCVaiACAJQCUAJBDWoYAgEMAhgCQOVqGAIA5AJoAkCNaggCAIwCMAJAxWoIAkDJaAJBJWgCQNFqCAJAwWgCQM1oAkDZaggCAMgAAgDAAAJA8WgCQR1oAkDVaAJA3WgCQOVqCAIAxAACASQAAgDMAAIA8AACARwAAkDhaggCANAAAgDgAggCANgCCAIA1AIQAgDcAggCAOQCYAJBKWgCQTFqCAJBJWoIAgEoAAIBJAIIAgEwAkACQM1qGAJA1WoIAgDMAAJA3WoYAkDpaggCAOgCCAIA1AACANwCEAJA9WoIAgD0AiAD/LwA=');\n",
       "                        });\n",
       "                </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <div id='midiPlayerDiv4492'></div>\n",
       "                <link rel=\"stylesheet\" href=\"//cuthbertLab.github.io/music21j/css/m21.css\"\n",
       "                    type=\"text/css\" />\n",
       "                <script>\n",
       "                require.config({\n",
       "                    paths: {'music21': '//cuthbertLab.github.io/music21j/src/music21'}\n",
       "                });\n",
       "                require(['music21'], function() {\n",
       "                               mp = new music21.miditools.MidiPlayer();\n",
       "                               mp.addPlayer('#midiPlayerDiv4492');\n",
       "                               mp.base64Load('data:audio/midi;base64,TVRoZAAAAAYAAQACBABNVHJrAAAAFAD/UQMHoSAA/1gEBAIYCIgA/y8ATVRyawAAAZUA/wMAAOAAQADAAIgAkDxaAJB7WoIAgDwAAIB7AIgAkDVaggCANQCCAJA1WgCQN1qCAIA1AACANwCGAJAjWgCQJVqIAIAjAIIAgCUAggCQS1qEAJAfWoIAgEsAAIAfAIYAkDNaggCAMwAAkDVaggCQM1qCAIAzAIQAgDUAggCQOVqGAIA5AACQPlqCAIA+AACQQ1qCAIBDAACQOVqCAJBFWoIAgEUAggCQO1qCAJA8WoIAgDwAggCAOQAAgDsAigCQR1qCAIBHAIIAkFVahgCAVQAAkFhaggCQV1qCAIBYAIQAgFcAhgCQRVqCAIBFAIoAkEtaggCASwCCAJBRWoIAgFEAAJA0WoIAkDdaAJA5WoQAgDQAAJAzWoIAgDMAAJA2WgCQNVqCAIA2AIIAgDcAggCANQCCAIA5AIYAkD1aAJAlWoIAgD0AggCQNVoAkDNaggCANQCCAJA1WgCQJ1qEAIAlAACQKVqCAIApAIQAgDMAhgCANQCCAIAnAI4AkDVaggCANQCCAJA1WoIAgDUAiAD/LwA=');\n",
       "                        });\n",
       "                </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <div id='midiPlayerDiv5039'></div>\n",
       "                <link rel=\"stylesheet\" href=\"//cuthbertLab.github.io/music21j/css/m21.css\"\n",
       "                    type=\"text/css\" />\n",
       "                <script>\n",
       "                require.config({\n",
       "                    paths: {'music21': '//cuthbertLab.github.io/music21j/src/music21'}\n",
       "                });\n",
       "                require(['music21'], function() {\n",
       "                               mp = new music21.miditools.MidiPlayer();\n",
       "                               mp.addPlayer('#midiPlayerDiv5039');\n",
       "                               mp.base64Load('data:audio/midi;base64,TVRoZAAAAAYAAQACBABNVHJrAAAAFAD/UQMHoSAA/1gEBAIYCIgA/y8ATVRyawAAALsA/wMAAOAAQADAAIgAkDxaAJB7WoIAgDwAAIB7AJwAkDNaggCAMwAAkEdaggCQSVqCAIBHAIQAgEkAAJAmWoIAgCYAAJBrWoIAgGsAogCQL1qCAJAtWoQAgC8AAIAtAJAAkEFaAJBCWgCQP1qCAJBEWoQAkEVaggCARQCCAIBEAIIAgEEAAIBCAIIAgD8AlACQNVqEAJBXWoIAgDUAhACAVwCWAJBFWoIAgEUApgCQPVqEAIA9AIgA/y8A');\n",
       "                        });\n",
       "                </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <div id='midiPlayerDiv5974'></div>\n",
       "                <link rel=\"stylesheet\" href=\"//cuthbertLab.github.io/music21j/css/m21.css\"\n",
       "                    type=\"text/css\" />\n",
       "                <script>\n",
       "                require.config({\n",
       "                    paths: {'music21': '//cuthbertLab.github.io/music21j/src/music21'}\n",
       "                });\n",
       "                require(['music21'], function() {\n",
       "                               mp = new music21.miditools.MidiPlayer();\n",
       "                               mp.addPlayer('#midiPlayerDiv5974');\n",
       "                               mp.base64Load('data:audio/midi;base64,TVRoZAAAAAYAAQACBABNVHJrAAAAFAD/UQMHoSAA/1gEBAIYCIgA/y8ATVRyawAAATwA/wMAAOAAQADAAIgAkDxaAJB7WoIAgDwAAIB7AI4AkDtahACQPVoAkD5aggCQP1qCAIA9AACAPwCCAIA+AIIAgDsAggCQP1oAkEFaggCAPwAAgEEAhgCQUVqCAIBRAIoAkENahgCAQwCCAJBLWoYAgEsAjACQNVqCAJAfWgCQO1oAkDlaggCAHwAAgDsAAJAjWgCQOFqCAIA1AACQN1qCAIAjAIIAkCVaggCAOQAAgCUAAJA1WoQAgDgAAIA3AACANQCIAJBHWoIAkElahgCARwCCAJAhWgCQNVqCAIAhAIIAkCNaggCASQCIAIA1AACAIwCKAJAdWoIAgB0AhACQV1qEAIBXAIoAkDVaggCQM1qGAJA3WoIAgDUAAIAzAACANwCGAJAlWoIAgCUAkgCQd1qCAIB3AIgA/y8A');\n",
       "                        });\n",
       "                </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from music21 import midi\n",
    "for i in range(n_samples):\n",
    "    mf = midi.MidiFile()\n",
    "    mf.open(f'./compositions/composition{i}.mid') \n",
    "    mf.read()\n",
    "    mf.close()\n",
    "    s = midi.translate.midiFileToStream(mf)\n",
    "    s.show('midi')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate music based on an input midi file. \n",
    "This generates a music piece based on the input midi file.\n",
    "- make a midi file and place it in the input_midi folder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run function to convert midi file to png file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['input_midi\\\\tst.mid']\n"
     ]
    }
   ],
   "source": [
    "def extractNote(element):\n",
    "    return int(element.pitch.ps)\n",
    "\n",
    "def extractDuration(element):\n",
    "    return element.duration.quarterLength\n",
    "\n",
    "def get_notes(notes_to_parse):\n",
    "\n",
    "    \"\"\" Get all the notes and chords from the midi files in the ./midi_songs directory \"\"\"\n",
    "    durations = []\n",
    "    notes = []\n",
    "    start = []\n",
    "\n",
    "    for element in notes_to_parse:\n",
    "        if isinstance(element, note.Note):\n",
    "            if element.isRest:\n",
    "                continue\n",
    "\n",
    "            start.append(element.offset)\n",
    "            notes.append(extractNote(element))\n",
    "            durations.append(extractDuration(element))\n",
    "                \n",
    "        elif isinstance(element, chord.Chord):\n",
    "            if element.isRest:\n",
    "                continue\n",
    "            for chord_note in element:\n",
    "                start.append(element.offset)\n",
    "                durations.append(extractDuration(element))\n",
    "                notes.append(extractNote(chord_note))\n",
    "\n",
    "    return {\"start\":start, \"pitch\":notes, \"dur\":durations}\n",
    "\n",
    "def midi2image(midi_path, max_repetitions = float(\"inf\"), resolution = 0.25, lowerBoundNote = 21, upperBoundNote = 127, maxSongLength = 100):\n",
    "    mid = converter.parse(midi_path)\n",
    "\n",
    "    instruments = instrument.partitionByInstrument(mid)\n",
    "\n",
    "    data = {}\n",
    "\n",
    "    try:\n",
    "        i=0\n",
    "        for instrument_i in instruments.parts:\n",
    "            notes_to_parse = instrument_i.recurse()\n",
    "\n",
    "            notes_data = get_notes(notes_to_parse)\n",
    "            if len(notes_data[\"start\"]) == 0:\n",
    "                continue\n",
    "\n",
    "            if instrument_i.partName is None:\n",
    "                data[\"instrument_{}\".format(i)] = notes_data\n",
    "                i+=1\n",
    "            else:\n",
    "                data[instrument_i.partName] = notes_data\n",
    "\n",
    "    except:\n",
    "        notes_to_parse = mid.flat.notes\n",
    "        data[\"instrument_0\"] = get_notes(notes_to_parse)\n",
    "\n",
    "    for instrument_name, values in data.items():\n",
    "        # https://en.wikipedia.org/wiki/Scientific_pitch_notation#Similar_systems\n",
    "\n",
    "        pitches = values[\"pitch\"]\n",
    "        durs = values[\"dur\"]\n",
    "        starts = values[\"start\"]\n",
    "\n",
    "        index = 0\n",
    "        while index < max_repetitions:\n",
    "            matrix = np.zeros((upperBoundNote-lowerBoundNote,maxSongLength))\n",
    "\n",
    "\n",
    "            for dur, start, pitch in zip(durs, starts, pitches):\n",
    "                dur = int(dur/resolution)\n",
    "                start = int(start/resolution)\n",
    "\n",
    "                if not start > index*(maxSongLength+1) or not dur+start < index*maxSongLength:\n",
    "                    for j in range(start,start+dur):\n",
    "                        if j - index*maxSongLength >= 0 and j - index*maxSongLength < maxSongLength:\n",
    "                            matrix[pitch-lowerBoundNote,j - index*maxSongLength] = 255\n",
    "\n",
    "            if matrix.any(): # If matrix contains no notes (only zeros) don't save it\n",
    "                imwrite(midi_path.split(\"/\")[-1].replace(\".mid\",f\".png\"),matrix.astype(np.uint8))\n",
    "                index += 1\n",
    "            else:\n",
    "                break\n",
    "\n",
    "path = 'input_midi/*.mid'\n",
    "files = glob.glob(path)\n",
    "print(files)\n",
    "# midi to image\n",
    "for i in range(len(files)):\n",
    "    midi2image(files[i])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changes shape of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['input_midi\\\\tst.png']\n",
      "(10, 10)\n"
     ]
    }
   ],
   "source": [
    "path = 'input_midi/*.png'\n",
    "files = glob.glob(path)\n",
    "print(files)\n",
    "for i in range(len(files)):\n",
    "    basewidth = 10\n",
    "    img = Image.open(files[i])\n",
    "    hsize = 10\n",
    "    img = img.resize((basewidth,hsize), Image.ANTIALIAS)\n",
    "    print(img.size)\n",
    "    img.save(files[i])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter the number of the file that you want to generate music for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number\t file name\n",
      "0 \t input_midi\\tst.png\n"
     ]
    }
   ],
   "source": [
    "print('number\\t file name')\n",
    "for i in range(len(files)):\n",
    "    \n",
    "    print(i,'\\t', files[i])\n",
    "\n",
    "midi = int(input(\"Enter the midi file number you want a sequel to: \"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gets the pixels of the image so that it can be used as input for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size: (1, 10, 10, 1)\n"
     ]
    }
   ],
   "source": [
    "def access_images(path):\n",
    "    pixels = []\n",
    "    imgs = []\n",
    "    if 'png' in path:\n",
    "        try:\n",
    "            img = Image.open(path, 'r')\n",
    "            img = img.convert('1')\n",
    "            pix = np.array(img.getdata())\n",
    "            pix = pix.astype('float32')\n",
    "            pix /= 255.0\n",
    "            pixels.append(pix.reshape(10,10,1))\n",
    "            imgs.append(img)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    return np.array(pixels),imgs\n",
    "\n",
    "\n",
    "pixels_test, imgs_test = access_images(files[midi])\n",
    "\n",
    "print(\"size:\", pixels_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "change the shape of the image to the shape that the model expects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\antje\\anaconda3\\envs\\musegan\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:470: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n"
     ]
    }
   ],
   "source": [
    "# reshape image pixels to 2D array\n",
    "pixels_test = pixels_test.reshape(10*10,1)\n",
    "\n",
    "# perform PCA with 100 components\n",
    "pca = PCA(n_components=1, svd_solver='full')\n",
    "pca_model = pca.fit(pixels_test)\n",
    "latent_points_test = pca_model.transform(pixels_test)\n",
    "\n",
    "# # reshape latent_points to (1, 100)\n",
    "latent_points_test = latent_points_test.reshape(1, 100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generates samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 100\n",
    "n_samples = 1\n",
    "def generated_samples(g_model, latent_points_test=latent_points_test):\n",
    "    for i in range(n_samples):\n",
    "        latent_points_test += 0.05 * tf.random.uniform(tf.shape(latent_points_test))\n",
    "        Array = randn(100*1)\n",
    "        Array = Array.reshape(1, 100)\n",
    "        Array = Array*0.4\n",
    "        print(\"array \",Array.shape)\n",
    "        print(\"latent \",latent_points_test.shape)\n",
    "        x_input = latent_points_test + Array\n",
    "        print(\"x_input \", x_input.shape)\n",
    "    return x_input\n",
    "\n",
    "model = g_model\n",
    "latent_points = generated_samples(latent_dim,n_samples, latent_points_test)\n",
    "X = g_model.predict(latent_points)\n",
    "print(X.shape)\n",
    "\n",
    "for i in range(n_samples):\n",
    "    # X = generated_samples(g_model, n_samples=n_samples)\n",
    "    array = np.array(X[i].reshape(106,106),dtype = np.uint8)\n",
    "    array*= 255\n",
    "    new_image = Image.fromarray(array,'L')\n",
    "    new_image = new_image.save(f'./compositions/composition_examplebased{i}.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converts the samples to midi files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_samples):\n",
    "    image2midi(f'./compositions/composition_examplebased{i}.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plays the midi files. the midi files are in the folder compositions. The filename looks like this: \n",
    "- composition_examplebased[number of different midifiles].mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <div id='midiPlayerDiv6239'></div>\n",
       "                <link rel=\"stylesheet\" href=\"//cuthbertLab.github.io/music21j/css/m21.css\"\n",
       "                    type=\"text/css\" />\n",
       "                <script>\n",
       "                require.config({\n",
       "                    paths: {'music21': '//cuthbertLab.github.io/music21j/src/music21'}\n",
       "                });\n",
       "                require(['music21'], function() {\n",
       "                               mp = new music21.miditools.MidiPlayer();\n",
       "                               mp.addPlayer('#midiPlayerDiv6239');\n",
       "                               mp.base64Load('data:audio/midi;base64,TVRoZAAAAAYAAQACBABNVHJrAAAAFAD/UQMHoSAA/1gEBAIYCIgA/y8ATVRyawAAABoA/wMAAOAAQADAAIgAkDxaggCAPACIAP8vAA==');\n",
       "                        });\n",
       "                </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <div id='midiPlayerDiv6296'></div>\n",
       "                <link rel=\"stylesheet\" href=\"//cuthbertLab.github.io/music21j/css/m21.css\"\n",
       "                    type=\"text/css\" />\n",
       "                <script>\n",
       "                require.config({\n",
       "                    paths: {'music21': '//cuthbertLab.github.io/music21j/src/music21'}\n",
       "                });\n",
       "                require(['music21'], function() {\n",
       "                               mp = new music21.miditools.MidiPlayer();\n",
       "                               mp.addPlayer('#midiPlayerDiv6296');\n",
       "                               mp.base64Load('data:audio/midi;base64,TVRoZAAAAAYAAQACBABNVHJrAAAAFAD/UQMHoSAA/1gEBAIYCIgA/y8ATVRyawAAABoA/wMAAOAAQADAAIgAkDxaggCAPACIAP8vAA==');\n",
       "                        });\n",
       "                </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <div id='midiPlayerDiv6353'></div>\n",
       "                <link rel=\"stylesheet\" href=\"//cuthbertLab.github.io/music21j/css/m21.css\"\n",
       "                    type=\"text/css\" />\n",
       "                <script>\n",
       "                require.config({\n",
       "                    paths: {'music21': '//cuthbertLab.github.io/music21j/src/music21'}\n",
       "                });\n",
       "                require(['music21'], function() {\n",
       "                               mp = new music21.miditools.MidiPlayer();\n",
       "                               mp.addPlayer('#midiPlayerDiv6353');\n",
       "                               mp.base64Load('data:audio/midi;base64,TVRoZAAAAAYAAQACBABNVHJrAAAAFAD/UQMHoSAA/1gEBAIYCIgA/y8ATVRyawAAABoA/wMAAOAAQADAAIgAkDxaggCAPACIAP8vAA==');\n",
       "                        });\n",
       "                </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <div id='midiPlayerDiv6410'></div>\n",
       "                <link rel=\"stylesheet\" href=\"//cuthbertLab.github.io/music21j/css/m21.css\"\n",
       "                    type=\"text/css\" />\n",
       "                <script>\n",
       "                require.config({\n",
       "                    paths: {'music21': '//cuthbertLab.github.io/music21j/src/music21'}\n",
       "                });\n",
       "                require(['music21'], function() {\n",
       "                               mp = new music21.miditools.MidiPlayer();\n",
       "                               mp.addPlayer('#midiPlayerDiv6410');\n",
       "                               mp.base64Load('data:audio/midi;base64,TVRoZAAAAAYAAQACBABNVHJrAAAAFAD/UQMHoSAA/1gEBAIYCIgA/y8ATVRyawAAABoA/wMAAOAAQADAAIgAkDxaggCAPACIAP8vAA==');\n",
       "                        });\n",
       "                </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <div id='midiPlayerDiv6467'></div>\n",
       "                <link rel=\"stylesheet\" href=\"//cuthbertLab.github.io/music21j/css/m21.css\"\n",
       "                    type=\"text/css\" />\n",
       "                <script>\n",
       "                require.config({\n",
       "                    paths: {'music21': '//cuthbertLab.github.io/music21j/src/music21'}\n",
       "                });\n",
       "                require(['music21'], function() {\n",
       "                               mp = new music21.miditools.MidiPlayer();\n",
       "                               mp.addPlayer('#midiPlayerDiv6467');\n",
       "                               mp.base64Load('data:audio/midi;base64,TVRoZAAAAAYAAQACBABNVHJrAAAAFAD/UQMHoSAA/1gEBAIYCIgA/y8ATVRyawAAABoA/wMAAOAAQADAAIgAkDxaggCAPACIAP8vAA==');\n",
       "                        });\n",
       "                </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from music21 import midi\n",
    "for i in range(n_samples):\n",
    "    mf = midi.MidiFile()\n",
    "    mf.open(f'./compositions/composition_examplebased{i}.mid') \n",
    "    mf.read()\n",
    "    mf.close()\n",
    "    s = midi.translate.midiFileToStream(mf)\n",
    "    s.show('midi')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creat a song with a synth sound from the magenta model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a new conda environment with python 3.8\n",
    "And install the following packages:\n",
    "- magenta\n",
    "- tensorflow_gan"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Donwload mymodel: [download]()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Put the downloaded mymodel in the mymodel folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gansynth_generate --ckpt_dir=mymodel --output_dir=generated_song --midi_file=compositions/composition_examplebased0.mid"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "musegan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eb8a2dceb528f9540b7247c6209aad497dfa4e422467a31547e98cda4b526ba3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
